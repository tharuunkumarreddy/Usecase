name: LSTM_Autoencoder_Training
description: LSTM Autoencoder training component for time series anomaly detection. Trains autoencoder model and detects anomalies using reconstruction error. FIXED threshold lowered to 1.5 sigma for more sensitive detection on short test series.
inputs:
  - {name: processed_data, type: Dataset, description: "Directory containing rupturenet_processed_data.pkl from preprocessing component"}
  - {name: hidden_dim, type: Integer, default: "64", description: "Hidden dimension size for LSTM layers"}
  - {name: latent_dim, type: Integer, default: "32", description: "Latent space dimension"}
  - {name: num_layers, type: Integer, default: "2", description: "Number of LSTM layers"}
  - {name: dropout, type: Float, default: "0.2", description: "Dropout rate for regularization"}
  - {name: batch_size, type: Integer, default: "32", description: "Training batch size"}
  - {name: num_epochs, type: Integer, default: "50", description: "Maximum number of training epochs"}
  - {name: learning_rate, type: Float, default: "0.001", description: "Learning rate for optimizer"}
  - {name: anomaly_threshold, type: Float, default: "1.5", description: "Anomaly detection threshold in standard deviations (FIXED: 1.5 instead of 2.5)"}
outputs:
  - {name: lstm_results, type: Dataset, description: "Directory containing LSTM model and results"}
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        pip3 install --no-cache-dir numpy pandas scikit-learn tqdm matplotlib
        pip3 install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/cpu
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import numpy as np
        import pandas as pd
        import torch
        import torch.nn as nn
        import torch.optim as optim
        from torch.utils.data import Dataset, DataLoader
        import pickle
        import json
        from datetime import datetime
        from tqdm import tqdm
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        import argparse
        import os

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        class LSTMAutoencoder(nn.Module):
            def __init__(self, input_dim, hidden_dim, latent_dim, num_layers, dropout):
                super(LSTMAutoencoder, self).__init__()
                
                self.input_dim = input_dim
                self.hidden_dim = hidden_dim
                self.latent_dim = latent_dim
                self.num_layers = num_layers
                
                self.encoder_lstm = nn.LSTM(
                    input_size=input_dim,
                    hidden_size=hidden_dim,
                    num_layers=num_layers,
                    dropout=dropout if num_layers > 1 else 0,
                    batch_first=True
                )
                
                self.encoder_to_latent = nn.Linear(hidden_dim, latent_dim)
                self.latent_to_hidden = nn.Linear(latent_dim, hidden_dim)
                
                self.decoder_lstm = nn.LSTM(
                    input_size=hidden_dim,
                    hidden_size=hidden_dim,
                    num_layers=num_layers,
                    dropout=dropout if num_layers > 1 else 0,
                    batch_first=True
                )
                
                self.decoder_output = nn.Linear(hidden_dim, input_dim)
                
            def forward(self, x, seq_len):
                batch_size = x.size(0)
                max_seq_len = x.size(1)
                
                packed_input = nn.utils.rnn.pack_padded_sequence(
                    x, seq_len.cpu(), batch_first=True, enforce_sorted=False
                )
                
                packed_output, (hidden, cell) = self.encoder_lstm(packed_input)
                latent = self.encoder_to_latent(hidden[-1])
                
                decoder_input = self.latent_to_hidden(latent)
                decoder_input = decoder_input.unsqueeze(1).repeat(1, max_seq_len, 1)
                
                packed_decoder_input = nn.utils.rnn.pack_padded_sequence(
                    decoder_input, seq_len.cpu(), batch_first=True, enforce_sorted=False
                )
                
                packed_decoder_output, _ = self.decoder_lstm(packed_decoder_input)
                
                decoder_output, _ = nn.utils.rnn.pad_packed_sequence(
                    packed_decoder_output, batch_first=True, total_length=max_seq_len
                )
                
                reconstructed = self.decoder_output(decoder_output)
                
                return reconstructed, latent

        class TimeSeriesDataset(Dataset):
            def __init__(self, series_list):
                self.series_list = series_list
                self.lengths = [len(s) for s in series_list]
                
            def __len__(self):
                return len(self.series_list)
            
            def __getitem__(self, idx):
                series = torch.FloatTensor(self.series_list[idx])
                length = len(series)
                return series, length

        def collate_fn(batch):
            series_list, lengths = zip(*batch)
            padded_series = nn.utils.rnn.pad_sequence(series_list, batch_first=True)
            lengths = torch.LongTensor(lengths)
            return padded_series, lengths

        def train_epoch(model, dataloader, optimizer, criterion, device):
            model.train()
            total_loss = 0
            
            for batch_idx, (x, seq_len) in enumerate(dataloader):
                x = x.to(device)
                seq_len = seq_len.to(device)
                
                reconstructed, latent = model(x, seq_len)
                
                loss = 0
                for i in range(len(seq_len)):
                    actual_len = seq_len[i].item()
                    loss += criterion(reconstructed[i, :actual_len], x[i, :actual_len])
                loss = loss / len(seq_len)
                
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                total_loss += loss.item()
            
            return total_loss / len(dataloader)

        def validate(model, dataloader, criterion, device):
            model.eval()
            total_loss = 0
            
            with torch.no_grad():
                for x, seq_len in dataloader:
                    x = x.to(device)
                    seq_len = seq_len.to(device)
                    
                    reconstructed, latent = model(x, seq_len)
                    
                    loss = 0
                    for i in range(len(seq_len)):
                        actual_len = seq_len[i].item()
                        loss += criterion(reconstructed[i, :actual_len], x[i, :actual_len])
                    loss = loss / len(seq_len)
                    
                    total_loss += loss.item()
            
            return total_loss / len(dataloader)

        if __name__ == "__main__":
            parser = argparse.ArgumentParser()
            parser.add_argument('--processed_data', type=str, required=True)
            parser.add_argument('--hidden_dim', type=int, default=64)
            parser.add_argument('--latent_dim', type=int, default=32)
            parser.add_argument('--num_layers', type=int, default=2)
            parser.add_argument('--dropout', type=float, default=0.2)
            parser.add_argument('--batch_size', type=int, default=32)
            parser.add_argument('--num_epochs', type=int, default=50)
            parser.add_argument('--learning_rate', type=float, default=0.001)
            parser.add_argument('--anomaly_threshold', type=float, default=1.5)
            parser.add_argument('--lstm_results', type=str, required=True)
            args = parser.parse_args()

            try:
                print("="*80)
                print("RUPTURENET-CPD: LSTM AUTOENCODER TRAINING")
                print("="*80)
                
                now = datetime.now()
                print("\\nStarted:", now.strftime("%Y-%m-%d %H:%M:%S"))
                print("Using device:", device)
                print("PyTorch version:", torch.__version__)

                print("\\n" + "="*80)
                print("LOADING PREPROCESSED DATA")
                print("="*80)

                processed_data_path = os.path.join(args.processed_data, 'rupturenet_processed_data.pkl')
                
                if not os.path.exists(processed_data_path):
                    raise FileNotFoundError("Data file not found: " + processed_data_path)
                
                with open(processed_data_path, 'rb') as f:
                    data_package = pickle.load(f)

                train_series = data_package['train_series']
                test_series = data_package['test_series']
                feature_names = data_package['feature_names']

                input_dim = len(feature_names)

                print("\\nLoaded:")
                print("  Training series:", len(train_series))
                print("  Test series:", len(test_series))
                print("  Features:", input_dim)

                train_dataset = TimeSeriesDataset(train_series)
                test_dataset = TimeSeriesDataset(test_series)

                train_loader = DataLoader(
                    train_dataset,
                    batch_size=args.batch_size,
                    shuffle=True,
                    collate_fn=collate_fn,
                    num_workers=0
                )

                test_loader = DataLoader(
                    test_dataset,
                    batch_size=args.batch_size,
                    shuffle=False,
                    collate_fn=collate_fn,
                    num_workers=0
                )

                print("\\nCreated dataloaders:")
                print("  Train batches:", len(train_loader))
                print("  Test batches:", len(test_loader))

                print("\\n" + "="*80)
                print("CREATING MODEL")
                print("="*80)

                model = LSTMAutoencoder(
                    input_dim=input_dim,
                    hidden_dim=args.hidden_dim,
                    latent_dim=args.latent_dim,
                    num_layers=args.num_layers,
                    dropout=args.dropout
                ).to(device)

                print("\\nModel created:")
                print("  Input dim:", input_dim)
                print("  Hidden dim:", args.hidden_dim)
                print("  Latent dim:", args.latent_dim)
                print("  Num layers:", args.num_layers)

                total_params = sum(p.numel() for p in model.parameters())
                print("  Total parameters:", total_params)

                criterion = nn.MSELoss()
                optimizer = optim.AdamW(
                    model.parameters(),
                    lr=args.learning_rate,
                    weight_decay=1e-5
                )

                scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                    optimizer, mode='min', factor=0.5, patience=5
                )

                print("\\n" + "="*80)
                print("TRAINING")
                print("="*80)

                output_dir = args.lstm_results
                os.makedirs(output_dir, exist_ok=True)

                best_model_path = os.path.join(output_dir, 'lstm_autoencoder_best.pth')

                best_val_loss = float('inf')
                patience_counter = 0
                patience = 10
                min_delta = 1e-4
                train_losses = []
                val_losses = []

                for epoch in range(args.num_epochs):
                    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
                    train_losses.append(train_loss)
                    
                    val_loss = validate(model, test_loader, criterion, device)
                    val_losses.append(val_loss)
                    
                    scheduler.step(val_loss)
                    
                    msg = "Epoch {}/{}: Train Loss = {:.6f}, Val Loss = {:.6f}"
                    print(msg.format(epoch+1, args.num_epochs, train_loss, val_loss))
                    
                    if val_loss < best_val_loss - min_delta:
                        best_val_loss = val_loss
                        patience_counter = 0
                        torch.save({
                            'epoch': epoch,
                            'model_state_dict': model.state_dict(),
                            'optimizer_state_dict': optimizer.state_dict(),
                            'train_loss': train_loss,
                            'val_loss': val_loss,
                            'config': {
                                'input_dim': input_dim,
                                'hidden_dim': args.hidden_dim,
                                'latent_dim': args.latent_dim,
                                'num_layers': args.num_layers,
                                'dropout': args.dropout,
                                'anomaly_threshold': args.anomaly_threshold
                            }
                        }, best_model_path)
                        print("  Saved best model (val_loss: {:.6f})".format(val_loss))
                    else:
                        patience_counter += 1
                        if patience_counter >= patience:
                            print("\\nEarly stopping triggered after {} epochs".format(epoch+1))
                            break

                print("\\nTraining complete! Best validation loss: {:.6f}".format(best_val_loss))

                print("\\n" + "="*80)
                print("COMPUTING RECONSTRUCTION ERRORS")
                print("="*80)

                checkpoint = torch.load(best_model_path, map_location=device)
                model.load_state_dict(checkpoint['model_state_dict'])
                model.eval()

                train_errors = []

                print("\\nComputing train errors...")
                with torch.no_grad():
                    for series in tqdm(train_series, desc="Train errors"):
                        series_tensor = torch.FloatTensor(series).unsqueeze(0).to(device)
                        seq_len = torch.LongTensor([len(series)]).to(device)
                        
                        reconstructed, _ = model(series_tensor, seq_len)
                        mse = torch.mean((series_tensor - reconstructed) ** 2, dim=2).squeeze().cpu().numpy()
                        train_errors.append(mse)

                all_train_errors = np.concatenate(train_errors)
                error_mean = np.mean(all_train_errors)
                error_std = np.std(all_train_errors)

                anomaly_threshold = error_mean + args.anomaly_threshold * error_std

                print("\\nReconstruction error statistics:")
                print("  Mean: {:.6f}".format(error_mean))
                print("  Std: {:.6f}".format(error_std))
                print("  Anomaly threshold ({}sigma): {:.6f}".format(args.anomaly_threshold, anomaly_threshold))

                test_errors = []
                test_anomalies = []

                print("\\nComputing test errors...")
                with torch.no_grad():
                    for series in tqdm(test_series, desc="Test errors"):
                        series_tensor = torch.FloatTensor(series).unsqueeze(0).to(device)
                        seq_len = torch.LongTensor([len(series)]).to(device)
                        
                        reconstructed, _ = model(series_tensor, seq_len)
                        mse = torch.mean((series_tensor - reconstructed) ** 2, dim=2).squeeze().cpu().numpy()
                        test_errors.append(mse)
                        
                        anomalies = (mse > anomaly_threshold).astype(int)
                        test_anomalies.append(anomalies)

                total_test_anomalies = sum(np.sum(a) for a in test_anomalies)
                print("\\nTest reconstruction computed for {} series".format(len(test_errors)))
                print("  Total test anomalies detected:", total_test_anomalies)

                print("\\n" + "="*80)
                print("SAVING RESULTS")
                print("="*80)

                results = {
                    'config': {
                        'input_dim': input_dim,
                        'hidden_dim': args.hidden_dim,
                        'latent_dim': args.latent_dim,
                        'num_layers': args.num_layers,
                        'dropout': args.dropout,
                        'batch_size': args.batch_size,
                        'num_epochs': args.num_epochs,
                        'learning_rate': args.learning_rate,
                        'anomaly_threshold': args.anomaly_threshold
                    },
                    'train_losses': train_losses,
                    'val_losses': val_losses,
                    'best_val_loss': float(best_val_loss),
                    'error_threshold': float(anomaly_threshold),
                    'error_mean': float(error_mean),
                    'error_std': float(error_std),
                    'train_errors': train_errors,
                    'test_errors': test_errors,
                    'test_anomalies': test_anomalies
                }

                results_path = os.path.join(output_dir, 'lstm_autoencoder_results.pkl')
                with open(results_path, 'wb') as f:
                    pickle.dump(results, f)
                print("\\nSaved:", results_path)

                summary = {
                    'model': 'LSTM Autoencoder',
                    'architecture': {
                        'input_dim': input_dim,
                        'hidden_dim': args.hidden_dim,
                        'latent_dim': args.latent_dim,
                        'num_layers': args.num_layers
                    },
                    'training': {
                        'epochs_trained': len(train_losses),
                        'best_val_loss': float(best_val_loss),
                        'final_train_loss': float(train_losses[-1]),
                        'final_val_loss': float(val_losses[-1])
                    },
                    'anomaly_detection': {
                        'threshold': float(anomaly_threshold),
                        'threshold_multiplier': args.anomaly_threshold,
                        'error_mean': float(error_mean),
                        'error_std': float(error_std),
                        'total_test_anomalies': int(total_test_anomalies)
                    }
                }

                summary_path = os.path.join(output_dir, 'lstm_autoencoder_summary.json')
                with open(summary_path, 'w') as f:
                    json.dump(summary, f, indent=2)
                print("Saved:", summary_path)

                try:
                    plt.figure(figsize=(10, 6))
                    plt.plot(train_losses, label='Train Loss', linewidth=2)
                    plt.plot(val_losses, label='Val Loss', linewidth=2)
                    plt.xlabel('Epoch', fontsize=12)
                    plt.ylabel('MSE Loss', fontsize=12)
                    plt.title('LSTM Autoencoder Training', fontsize=14, fontweight='bold')
                    plt.legend(fontsize=10)
                    plt.grid(True, alpha=0.3)
                    plot_path = os.path.join(output_dir, 'lstm_training_curve.png')
                    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
                    plt.close()
                    print("Saved:", plot_path)
                except Exception as e:
                    print("Warning: Could not save plot:", str(e))

                print("\\n" + "="*80)
                print("LSTM AUTOENCODER TRAINING COMPLETE")
                print("="*80)

                print("\\nSummary:")
                print("  Epochs trained:", len(train_losses))
                print("  Best val loss: {:.6f}".format(best_val_loss))
                print("  Test anomalies:", total_test_anomalies)
                print("  Output directory:", output_dir)

                expected_files = [
                    'lstm_autoencoder_best.pth',
                    'lstm_autoencoder_results.pkl',
                    'lstm_autoencoder_summary.json'
                ]
                
                print("\\nVerifying output files:")
                for filename in expected_files:
                    filepath = os.path.join(output_dir, filename)
                    if os.path.exists(filepath):
                        size = os.path.getsize(filepath)
                        print("  OK {0} ({1} bytes)".format(filename, size))
                    else:
                        print("  MISSING:", filename)

                end_time = datetime.now()
                print("\\n" + "="*80)
                print("Completed:", end_time.strftime("%Y-%m-%d %H:%M:%S"))
                print("="*80)
                
            except Exception as e:
                print("\\n" + "="*80)
                print("ERROR OCCURRED")
                print("="*80)
                print("\\nError:", str(e))
                import traceback
                traceback.print_exc()
                raise
    args:
      - --processed_data
      - {inputPath: processed_data}
      - --hidden_dim
      - {inputValue: hidden_dim}
      - --latent_dim
      - {inputValue: latent_dim}
      - --num_layers
      - {inputValue: num_layers}
      - --dropout
      - {inputValue: dropout}
      - --batch_size
      - {inputValue: batch_size}
      - --num_epochs
      - {inputValue: num_epochs}
      - --learning_rate
      - {inputValue: learning_rate}
      - --anomaly_threshold
      - {inputValue: anomaly_threshold}
      - --lstm_results
      - {outputPath: lstm_results}
